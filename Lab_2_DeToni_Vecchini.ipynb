{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0E8Oel9npUK"
   },
   "source": [
    "**Lab 2** for the course of *Selected Topics in Music and Acoustic Engineering* :\n",
    "\n",
    "***Machine Learning for Audio and Acoustic Engineering***\n",
    "---\n",
    "\n",
    "# **Before you start**\n",
    "\n",
    "*   Go to \"*File*\" --> \"*Save a copy in Drive*\"\n",
    "*   Open that copy (might open automatically)\n",
    "*   Then continue below\n",
    "\n",
    "# **Lab 2: Introduction to ML Methods in Audio**\n",
    "In this lab we will explore some well-known Machine Learning methods making use of the Scikit-Learn library. We'll go through matrix factorization methods and some popular supervised and unsupervised learning techniques.\n",
    "\n",
    "---\n",
    "\n",
    "# Exercise 1. Import libraries\n",
    "\n",
    "* We need a number of libraries. Import them once to use throughout the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4is6rZnMmrV5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "import librosa, librosa.display\n",
    "import IPython\n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9EsWq7RoR_n"
   },
   "source": [
    "---\n",
    "\n",
    "# Exercise 2. Fetch the Dataset\n",
    "\n",
    "*   ESC-50: a dataset for Environmental Sound Classification (https://github.com/karolpiczak/ESC-50, https://www.karolpiczak.com/papers/Piczak2015-ESC-Dataset.pdf)\n",
    " * 50 classes,  40 files per class, 5s clips\n",
    "*   Download & unzip the dataset running the cell below. This will take a minute. You will see the new files on the left (folder icon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Sxb_GsyRoTuL",
    "outputId": "a528ab01-5d7e-4719-9bb5-275de9f20bce"
   },
   "outputs": [],
   "source": [
    "#!curl -L -o master.zip https://github.com/karolpiczak/ESC-50/archive/master.zip\n",
    "#!unzip master.zip\n",
    "#!rm master.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVSD-B8hsc-2"
   },
   "source": [
    "---\n",
    "\n",
    "# Exercise 3. Metadata and analysis I\n",
    "\n",
    "***Tasks:***\n",
    "* Use pandas to read the csv file in *ESC-50-master/meta/*\n",
    "* Print the first elements of the csv. Pandas has a standard function for this.\n",
    "* Print the list of *unique* class labels in the dataset, and check whether there really are 50 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gwJsOZMsctx"
   },
   "outputs": [],
   "source": [
    "# Load and read the dataset\n",
    "fn_csv = 'ESC-50-master/meta/esc50.csv'\n",
    "df = pd.read_csv(fn_csv)\n",
    "\n",
    "# Print the head of the csv\n",
    "print(\"Head of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Print the unique class labels and their number\n",
    "unique_classes = df['category'].unique()\n",
    "print(f\"Classes: \\n ({unique_classes})\")\n",
    "print(f\"The number of unique classes is ({len(unique_classes)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncgihxZFtSiZ"
   },
   "source": [
    "Expected output:\n",
    "```\n",
    "    filename            fold  target  category        esc10   src_file  take\n",
    "0   1-100032-A-0.wav    1     0       dog             True    100032    A\n",
    "1   1-100038-A-14.wav   1     14      chirping_birds  False   100038    A\n",
    "2   1-100210-A-36.wav   1     36      vacuum_cleaner  False   100210    A\n",
    "3   1-100210-B-36.wav   1     36      vacuum_cleaner  False   100210    B\n",
    "4   1-101296-A-19.wav   1     19      thunderstorm    False   101296    A\n",
    "```\n",
    "\n",
    "```\n",
    "Unique classes: ['dog' 'chirping_birds' ... ]\n",
    "Count: 50\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXKHVTX6thTW"
   },
   "source": [
    "---\n",
    "\n",
    "# Exercise 4. Metadata and analysis II\n",
    "\n",
    "* View and listen to some examples in the dataset to get a \"feeling\" for the sound classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5uuViWVftn05"
   },
   "outputs": [],
   "source": [
    "# Setup filepaths\n",
    "file0 = os.path.join('ESC-50-master', 'audio', df['filename'][2])\n",
    "file1 = os.path.join('ESC-50-master', 'audio', df['filename'][3])\n",
    "file2 = os.path.join('ESC-50-master', 'audio', df['filename'][4])\n",
    "\n",
    "print(file0, os.path.exists(file0))\n",
    "print(file1, os.path.exists(file1))\n",
    "print(file2, os.path.exists(file2))\n",
    "\n",
    "# Show audio players\n",
    "print(df['category'][2])\n",
    "IPython.display.display(IPython.display.Audio(filename=file0))\n",
    "print(df['category'][3])\n",
    "IPython.display.display(IPython.display.Audio(filename=file1))\n",
    "print(df['category'][4])\n",
    "IPython.display.display(IPython.display.Audio(filename=file2))\n",
    "\n",
    "# Plot mel specs\n",
    "files = [file0, file1, file2]\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(18, 6))\n",
    "for i in range(3):\n",
    "    y, sr = librosa.load(files[i], sr=None, backend='soundfile')\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, y_axis='linear', x_axis='time', sr=sr, ax=ax[i])\n",
    "    ax[i].set(title='Power spec')\n",
    "    ax[i].label_outer()\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pxod2YzBvT4O"
   },
   "source": [
    "---\n",
    "\n",
    "# Exercise 5. ESC-5: Curation\n",
    "\n",
    "Let's select 2 classes (*our_classes=['dog', 'rooster']*) from ESC-50 to make things a bit faster.\n",
    "\n",
    "***Tasks:***\n",
    "* Collect all files that belong to *our_classes*.\n",
    "* Put the files and their respective classes in separate lists. Make sure their indices are equal (meaning: the value at index 3 of list *A* is related to the value at index 3 of list *B*).\n",
    "  * Idea 1: Use *df.values* to iterate over the rows of the csv\n",
    "  * Idea 2: Use *df.query('category in @our_classes')*\n",
    "* Print the first 5 elements of each list as (file, class)-tuples. Also, print the overall lengths of the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w-tk0PE2xQL9",
    "outputId": "f8f726ea-58a3-4794-acf7-3003c720d560"
   },
   "outputs": [],
   "source": [
    "our_classes = ['dog', 'rooster']  # Note: This is also a class map for later. \n",
    "esc5_X = []  # File list\n",
    "esc5_y = []  # Class list\n",
    "fn_csv = 'ESC-50-master/meta/esc50.csv'\n",
    "\n",
    "\n",
    "### START CODING ###\n",
    "df = pd.read_csv(fn_csv)\n",
    "...\n",
    "\n",
    "print( ...(esc5_X[:5], esc5_y[:5])... )\n",
    "print(f'Lengths: ...')\n",
    "### END CODING ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GJNqoqSxXG2"
   },
   "source": [
    "Expected output:\n",
    "```\n",
    "[('1-100032-A-0.wav', 'dog'), ('1-110389-A-0.wav', 'dog'), ('1-26806-A-1.wav', 'rooster'), ('1-27724-A-1.wav', 'rooster'), ('1-30226-A-0.wav', 'dog')]\n",
    "Lengths: esc5_X: 80, esc5_y: 80\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70ERvSja0MVZ"
   },
   "source": [
    "# Exercise 6. NMF Decomposition\n",
    "The following code picks one signal of class 'dog' and class 'rooster' and mix both signals together in a new array called 'audiomix'.\n",
    "\n",
    "**Note:** Listen to the signals and make sure the signal is active in most of the audio duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "id": "KtgZZTyTxafa",
    "outputId": "cbca7c66-5ddb-432f-febd-8e63da4857a1"
   },
   "outputs": [],
   "source": [
    "path = 'ESC-50-master/audio/'\n",
    "dogs_files = esc5_X[esc5_y=='dog']\n",
    "rooster_files = esc5_X[esc5_y=='rooster']\n",
    "\n",
    "### START CODING ###\n",
    "signal_0, sr = librosa.load(path + dogs_files[...])\n",
    "signal_1, sr = librosa.load(path + rooster_files[...])\n",
    "### END CODING ###\n",
    "\n",
    "print('Dog example')\n",
    "IPython.display.display(IPython.display.Audio(signal_0, rate=sr))\n",
    "print('Rooster example')\n",
    "IPython.display.display(IPython.display.Audio(signal_1, rate=sr))\n",
    "\n",
    "# Compute the mixture of the two signals\n",
    "audiomix = signal_0/np.max(signal_0) + signal_1/np.max(signal_1)\n",
    "audiomix = 0.5 * audiomix/np.max(audiomix)\n",
    "print('Mixture')\n",
    "IPython.display.display(IPython.display.Audio(audiomix, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVcHdkL55yge"
   },
   "source": [
    "Now let's compute the spectrogram of the mixture and decompose the magnitude information using NMF with 2 components (see librosa.decompose.decompose):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5JPhXDM_5yHy"
   },
   "outputs": [],
   "source": [
    "S = librosa.stft(audiomix)\n",
    "X, X_phase = librosa.magphase(S)\n",
    "### START CODING ###\n",
    "...\n",
    "print(W.shape, H.shape)\n",
    "### END CODING ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTawlB0B7hA6"
   },
   "source": [
    "Expected output:\n",
    "```\n",
    "(1025, 2) (2, 216)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WUWzovn70sJ"
   },
   "source": [
    "Compare the original and approximated spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z54CjN3P7nOm"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "#original\n",
    "plt.subplot(1,2,1)\n",
    "librosa.display.specshow(20*np.log10(X+np.finfo(float).eps), sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "plt.title('Original')\n",
    "plt.colorbar()\n",
    "\n",
    "#after NMF\n",
    "plt.subplot(1,2,2)\n",
    "librosa.display.specshow(20*np.log10(np.dot(W,H)+np.finfo(float).eps), sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "plt.title('NMF')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeHa4SUh8QS6"
   },
   "source": [
    "Now let's represent the learned spectral patterns and temporal activations for each component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGSA4kcq8Q3W"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "t_frames = librosa.frames_to_time(np.arange(H.shape[1]))\n",
    "plot_iter=1\n",
    "for i in range(n_components):\n",
    "  plt.subplot(2,n_components,plot_iter)\n",
    "  plt.plot(20*np.log10(W[:,i]+np.finfo(float).eps))\n",
    "  plt.xlabel('Freq[Hz]')\n",
    "  plt.title('Spectral Pattern (Basis) {}'.format(i))\n",
    "  plt.ylim(bottom=-70);\n",
    "  plot_iter += 1\n",
    "\n",
    "  plt.subplot(2,n_components,plot_iter)\n",
    "  plt.plot(t_frames, H[i,:])\n",
    "  plt.xlabel('Time [s]')\n",
    "  plt.title('Temporal Activation {}'.format(i));\n",
    "  plot_iter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRoBXKXF8z0M"
   },
   "source": [
    "Finally let's reconstruct the temporal signal of each component (use the phase information of the original mix signal) and listen to the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1FoWIBl82ss"
   },
   "outputs": [],
   "source": [
    "reconstructed_signals = []\n",
    "\n",
    "### START CODING ###\n",
    "for i in range(n_components):\n",
    "  component = ...\n",
    "\n",
    "  #come back to the time domain\n",
    "  print(f'Component: {i}')\n",
    "  IPython.display.display(IPython.display.Audio(librosa.istft(component), rate=sr))\n",
    "\n",
    "### END CODING ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "he4i8IUw_uuE"
   },
   "source": [
    "# Exercise 7. Harmonic-Percussive Decomposition\n",
    "Now, apply librosa's harmonic-percussive source separation to extract again two components.\n",
    "**Tasks**\n",
    "*   Compute the harmonic-percussive (see librosa.decompose.hps)\n",
    "*   Display the harmonic and the percussive spectrograms\n",
    "*   Listen to the obtained results\n",
    "*   Discuss the differences between the standard NMF and the Harmonic-Percussive separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qy4UYHT5_yOV"
   },
   "outputs": [],
   "source": [
    "### START CODING ###\n",
    "Hmm, Prs = ...\n",
    "...\n",
    "\n",
    "IPython.display.display(IPython.display.Audio(librosa.istft(Hmm), rate=sr))\n",
    "IPython.display.display(IPython.display.Audio(librosa.istft(Prs), rate=sr))\n",
    "### END CODING ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXrEWgm6CkY-"
   },
   "source": [
    "# Exercise 8. Feature Extraction\n",
    "Compute the mean ZCR and standard deviation of the spectral flatness for the examples in signals_0 (dogs) and signals_1 (rooster). Define a function to extract those features (call it 'extract_features') and store the extracted features into two arrays: 'dog_features' and 'rooster_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEHelBhQCx-D"
   },
   "outputs": [],
   "source": [
    "# Function definition\n",
    "def extract_features(signal):\n",
    "  ### START CODING ###\n",
    "  ...\n",
    "  return ...\n",
    "  ### END COD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6dmMmF0C51t"
   },
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "dog_features = np.array([extract_features(x) for x in signal_0])\n",
    "rooster_features = np.array([extract_features(x) for x in signal_1])\n",
    "\n",
    "print(dog_features.shape) #40 samples and 2 feature each\n",
    "print(rooster_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2hz9K-OC-RG"
   },
   "source": [
    "Expected output:\n",
    "```\n",
    "(40, 2)\n",
    "(40, 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNbp4XS4DNLH"
   },
   "source": [
    "Represent the histograms for each feature for the two classes and discuss which of the two features seems to be better for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onpI-W_jDDI6"
   },
   "outputs": [],
   "source": [
    "# First feature (ZCR)\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.hist(dog_features[:,0], color='b', alpha=0.5, bins=10)\n",
    "plt.hist(rooster_features[:,0], color='r', alpha=0.5, bins=10)\n",
    "plt.title('Zero Crossing Rate Feature')\n",
    "plt.legend(('dog','rooster'))\n",
    "plt.xlabel('Zero Crossing Rate - Mean')\n",
    "plt.ylabel('Count');\n",
    "\n",
    "# Second feature (SF)\n",
    "### START CODING ###\n",
    "...\n",
    "\n",
    "### END COD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADD YOUR DISCUSSION HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFhWt7gFD0Ro"
   },
   "source": [
    "# Exercise 9. Principal Component Analysis\n",
    "Redefine the feature extractor to extract 3 features, adding to the previous ones the mean value of the spectral centroid (see librosa.feature.spectral_centroid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHyGoSr2DW3W"
   },
   "outputs": [],
   "source": [
    "# Function definition\n",
    "def extract_features(signal):\n",
    "  ### START CODING ###\n",
    "  ...\n",
    "  return ...\n",
    "  ### END COD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhRV7I0_EDBP"
   },
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "dog_features = np.array([extract_features(x) for x in signal_0])\n",
    "rooster_features = np.array([extract_features(x) for x in signal_1])\n",
    "\n",
    "print(dog_features.shape) #40 samples and 3 feature each\n",
    "print(rooster_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3w8zk10sEGzA"
   },
   "source": [
    "Expected output:\n",
    "```\n",
    "(40, 3)\n",
    "(40, 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2TTGA7LUW-e"
   },
   "source": [
    "Create a matrix 'feature_table' stacking all the features a use sklearn 'scale' over such matrix. Create as well a label vector indicating the true label for each row of 'feature_table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HyTg7OTQEHkN"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    " ### START CODING ###\n",
    "feature_table = np.vstack(...)\n",
    "labels_gt = ...\n",
    "### END CODING ###\n",
    "\n",
    "# Scale the features\n",
    "training_features = scale(feature_table, axis=0)\n",
    "\n",
    "fig = plt.figure(figsize=(20,13))\n",
    "ax = fig.add_subplot(1,1,1, projection='3d')\n",
    "ax.scatter(training_features[labels_gt==1,0], training_features[labels_gt==1,1], training_features[labels_gt==1,2], c='b')\n",
    "ax.scatter(training_features[labels_gt==0,0], training_features[labels_gt==0,1], training_features[labels_gt==0,2], c='r');\n",
    "ax.legend(('dog','rooster'))\n",
    "ax.set_title('3D feature space scatterplot')\n",
    "ax.set_xlabel('Zero Crossing Rate - Mean')\n",
    "ax.set_ylabel('Spectral Flatness - Std')\n",
    "ax.set_zlabel('Spectral Centroid - Std');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8cSh0qRVdAK"
   },
   "source": [
    "Now apply PCA for reducing the dimensionality (see sklearn.decomposition.PCA) to two dimensions using whiten='true' and plot the corresponding scatterplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cu3A-K9GV3uS"
   },
   "outputs": [],
   "source": [
    "### START CODING ###\n",
    "\n",
    "#Create dimensionality reduction model\n",
    "...\n",
    "\n",
    "#Apply the tranformation\n",
    "Y = model.transform(X)\n",
    "\n",
    "#Plotting The Result\n",
    "plt.figure(figsize=(20,13))\n",
    "plt.scatter(Y[labels_gt==1,0], Y[labels_gt==1,1], c='b')\n",
    "plt.scatter(Y[labels_gt==0,0], Y[labels_gt==0,1], c='r')\n",
    "plt.title('After PCA - 2D')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(('dog', 'rooster'));\n",
    "#from 3d --> 2d\n",
    "### END COD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfxwXezkWL8U"
   },
   "source": [
    "# Exercise 10. Support Vector Machine\n",
    "\n",
    "Fit a linear SVM classifier with parameter C=1 to the PCA transformed data. Use the following helper function to draw the classifier hyperplanes of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSN4-F0AWTCS"
   },
   "outputs": [],
   "source": [
    "def draw_classplane(ax,model,xrange):\n",
    "  w = model.coef_[0]\n",
    "  b = model.intercept_[0]\n",
    "  a = -w[0] / w[1]\n",
    "  xx = np.linspace(xrange[0], xrange[1])\n",
    "  yy = a * xx - (b/ w[1])\n",
    "  margin = 1 / np.sqrt(np.sum(w** 2))\n",
    "  yy_down = yy - np.sqrt(1 + a ** 2) * margin\n",
    "  yy_up = yy + np.sqrt(1 + a ** 2) * margin\n",
    "  ax.plot(xx, yy, 'k-')\n",
    "  ax.plot(xx, yy_down, 'k--')\n",
    "  ax.plot(xx, yy_up, 'k--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uSX_XCr3WTxc"
   },
   "outputs": [],
   "source": [
    "### START CODING ###\n",
    "\n",
    "# Model fitting\n",
    "...\n",
    "\n",
    "# Model prediction\n",
    "...\n",
    "### END CODING ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b__tn8XEWoYO"
   },
   "source": [
    "Represent two subplots to compare the ground truth data and the classification result. Plot the classification hyperplanes and margin using the provided function 'draw_classplane'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QX3LzCdDWvJ1"
   },
   "outputs": [],
   "source": [
    "### START CODING ###\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "#Ground Truth Data\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(Y[labels_gt==1,0], Y[labels_gt==1,1], c='r')\n",
    "plt.scatter(Y[labels_gt==0,0], Y[labels_gt==0,1], c='b')\n",
    "plt.title('Ground Truth Data')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(('dog', 'rooster'))\n",
    "\n",
    "#Classification Result\n",
    "...\n",
    "### END CODING ###\n",
    "\n",
    "#Draw Hyperplane and margins\n",
    "draw_classplane(plt.gca(), model, (-2,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovSd8cp3XyvL"
   },
   "source": [
    "Compute the accuracy of the classification result (use sklearn.metrics.accuracy_score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1s3lw_FJX6ew"
   },
   "outputs": [],
   "source": [
    "acc = ...\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsgVMMbAYGQx"
   },
   "source": [
    "Expected output (might differ slightly):\n",
    "```\n",
    "Accuracy:  0.7875\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAH3MuZIYZ9N"
   },
   "source": [
    "Now, apply a RBF kernel for non-linear classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSWGLk-EYWvm"
   },
   "outputs": [],
   "source": [
    "### START CODING ###\n",
    "model = sklearn.svm.SVC(...)\n",
    "model.fit(...)\n",
    "labels = model.predict(Y)\n",
    "### END CODING ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HI0n-4q2Y6e6"
   },
   "source": [
    "Draw the resulting classification contour and compute the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XsgsFkNfY7IY"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,13))\n",
    "\n",
    "#for representation purposes\n",
    "h = 0.02\n",
    "x_min, x_max = Y[:,0].min() -1 , Y[:,0].max() +1\n",
    "y_min, y_max = Y[:,1].min() -1 , Y[:,1].max() +1\n",
    "xx, yy = np.meshgrid(np.arange(x_min,x_max,h), np.arange(y_min, y_max,h))\n",
    "\n",
    "#display the boundary by predicting on every point on the grid\n",
    "Z = model.predict(np.c_[ xx.ravel(), yy.ravel()])\n",
    "# Put the result into color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap = plt.cm.coolwarm, alpha = 0.8)\n",
    "\n",
    "plt.xlim(xx.min(), xx.max());\n",
    "plt.ylim(yy.min(), yy.max());\n",
    "\n",
    "plt.scatter(Y[labels==1,0],Y[labels==1,1],c='r')\n",
    "plt.scatter(Y[labels==0,0],Y[labels==0,1],c='b')\n",
    "plt.title('Classification Result with RBF Kernel with C ={}'.format(penalty))\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(('dog', 'rooster'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "siNFxqmRZBpa"
   },
   "outputs": [],
   "source": [
    "### START CODING ###\n",
    "acc = ...\n",
    "print('Accuracy: ', acc)\n",
    "### END CODING ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgTbtIDNZG1s"
   },
   "source": [
    "Expected output (might differ slightly):\n",
    "```\n",
    "Accuracy:  0.85\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGDA2vJTZWiU"
   },
   "source": [
    "Experiment with different parameters of C. Try different values also for the \"gamma\" parameter of the RBF kernel.\n",
    "\n",
    "Find a combination of parameters representing an overfitting and underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oddV4QbxZK1I"
   },
   "outputs": [],
   "source": [
    "### START CODING ###\n",
    "\n",
    "\n",
    "### END CODING ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcbCsKVOamcc"
   },
   "source": [
    "# Exercise 11. Support Vector Machine\n",
    "Cluster the PCA projected data into **2** groups using k-Means (see sklearn.cluster.KMeans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T54gLiHHazTQ"
   },
   "outputs": [],
   "source": [
    "### START CODING ###\n",
    "model = ...\n",
    "labels = ...\n",
    "### END CODING ###\n",
    "\n",
    "acc = sklearn.metrics.accuracy_score(labels_gt, labels)\n",
    "# Account for possible inversion\n",
    "if 1-acc > acc:\n",
    "  acc = 1-acc\n",
    "  labels = 1 - labels\n",
    "\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZ-ebqzDbc2V"
   },
   "source": [
    "Represent the scatterplots of the original data and the two resultant clusters. Plot the final k-Means centroids as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j3Io3IqebfDB"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "#Ground Truth Data\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(input[labels_gt==1,0], input[labels_gt==1,1], c='b')\n",
    "plt.scatter(input[labels_gt==0,0], input[labels_gt==0,1], c='r')\n",
    "plt.title('Original Data')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(('dog', 'rooster'))\n",
    "\n",
    "#Classification Result\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(input[labels==1,0], input[labels==1,1], c='b')\n",
    "plt.scatter(input[labels==0,0], input[labels==0,1], c='r')\n",
    "plt.title('Predicted Cluster')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.scatter(model.cluster_centers_[:,0] ,model.cluster_centers_[:,1], color='black', marker='^')\n",
    "plt.legend(('Class 1', 'Class 2', 'Centroids'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgBNnt0SbphM"
   },
   "source": [
    "#Exercise 12. k-NN\n",
    "Fit a k-NN classifier (sklearn.neighbors.KNeighborsClassifier) to the same data and experiment with different k parameters. Discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02XsDkM-bflG"
   },
   "outputs": [],
   "source": [
    "### START CODING ###\n",
    "...\n",
    "### END CODING ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR DISCUSSION HERE!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CMRM2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
